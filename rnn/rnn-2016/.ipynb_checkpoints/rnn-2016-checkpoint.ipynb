{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishadi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import required libraries\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatanating the date and the time stamp into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('DAT_MT_EURUSD_M1_2016.csv') as f:\n",
    "    reader = csv.reader(f)\n",
    "    with open('output.csv', 'w') as g:\n",
    "        writer = csv.writer(g)\n",
    "        for row in reader:\n",
    "            new_row = [' '.join([row[0], row[1]])] + row[2:]\n",
    "            writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "Date time stamp                                                             \n",
      "0                2016.01.03 17:01             1.08712             1.08712   \n",
      "1                2016.01.03 17:02             1.08708             1.08722   \n",
      "2                2016.01.03 17:03             1.08717             1.08723   \n",
      "3                2016.01.03 17:04             1.08718             1.08718   \n",
      "4                2016.01.03 17:05             1.08703             1.08716   \n",
      "\n",
      "                 Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "Date time stamp                                                  \n",
      "0                          1.08712              1.08712       0  \n",
      "1                          1.08708              1.08722       0  \n",
      "2                          1.08717              1.08723       0  \n",
      "3                          1.08711              1.08711       0  \n",
      "4                          1.08701              1.08712       0  \n",
      "                  Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "Date time stamp                                                             \n",
      "372673           2016.12.30 16:54             1.05178             1.05179   \n",
      "372674           2016.12.30 16:55             1.05175             1.05190   \n",
      "372675           2016.12.30 16:56             1.05167             1.05234   \n",
      "372676           2016.12.30 16:57             1.05170             1.05334   \n",
      "372677           2016.12.30 16:58             1.05278             1.05278   \n",
      "\n",
      "                 Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "Date time stamp                                                  \n",
      "372673                     1.05167              1.05174       0  \n",
      "372674                     1.05162              1.05169       0  \n",
      "372675                     1.05127              1.05192       0  \n",
      "372676                     1.05169              1.05282       0  \n",
      "372677                     1.05204              1.05224       0  \n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y.%m.%d %H:%M')\n",
    "dataset = read_csv('output.csv', date_parser=parse)\n",
    "#dataset = read_csv('output.csv')\n",
    "#dataset.drop('No', axis=1, inplace=True)\n",
    "\n",
    "# manually specify column names\n",
    "dataset.columns = ['Date time stamp', 'Bar OPEN Bid Quote', 'Bar HIGH Bid Quote', 'Bar LOW Bid Quote', 'Bar CLOSE Bid Quote', 'Volume']\n",
    "dataset.index.name = 'Date time stamp'\n",
    "\n",
    "# mark all NA values with 0\n",
    "dataset['Bar OPEN Bid Quote'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "#dataset = dataset[24:]\n",
    "\n",
    "# summarize first 5 rows\n",
    "print(dataset.head(5))\n",
    "print(dataset.tail(5))\n",
    "\n",
    "# save to file\n",
    "dataset.to_csv('2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the new “2016.csv” file and plots each series as a separate subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "# dataset = read_csv('2016.csv', header=0, index_col=0)\n",
    "# values = dataset.values\n",
    "\n",
    "# # specify columns to plot\n",
    "# groups = [0, 1, 2, 3, 4, 5]\n",
    "# i = 1\n",
    "\n",
    "# # plot each column\n",
    "# pyplot.figure()\n",
    "# for group in groups:\n",
    "# \tpyplot.subplot(len(groups), 1, i)\n",
    "# \tpyplot.plot(values[:, group])\n",
    "# \tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "# \ti += 1\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)   var1(t)\n",
      "1   0.000000   0.411048   0.409498   0.413382   0.411154        0.0  0.000003\n",
      "2   0.000003   0.410730   0.410291   0.413062   0.411945        0.0  0.000005\n",
      "3   0.000005   0.411444   0.410370   0.413779   0.412024        0.0  0.000008\n",
      "4   0.000008   0.411523   0.409974   0.413301   0.411075        0.0  0.000011\n",
      "5   0.000011   0.410335   0.409815   0.412505   0.411154        0.0  0.000013\n"
     ]
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('2016.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,0] = encoder.fit_transform(values[:,0])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM with 50 neurons in the first hidden layer \n",
    "#1 neuron in the output layer for predicting foreign currency rate\n",
    "#The input shape will be 1 time step with 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(372677, 1, 6) (372677,) (0, 1, 6) (0,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets# \n",
    "values = reframed.values\n",
    "n_train_minutes = 365 * 24 * 60\n",
    "train = values[:n_train_minutes, :]\n",
    "test = values[n_train_minutes:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model will be fit for 50 training epochs with a batch size of 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 372677 samples, validate on 0 samples\n",
      "Epoch 1/50\n",
      " - 7s - loss: 0.0073\n",
      "Epoch 2/50\n",
      " - 8s - loss: 0.0085\n",
      "Epoch 3/50\n",
      " - 9s - loss: 0.0049\n",
      "Epoch 4/50\n",
      " - 8s - loss: 0.0033\n",
      "Epoch 5/50\n",
      " - 6s - loss: 0.0027\n",
      "Epoch 6/50\n",
      " - 7s - loss: 0.0025\n",
      "Epoch 7/50\n",
      " - 7s - loss: 0.0024\n",
      "Epoch 8/50\n",
      " - 7s - loss: 0.0022\n",
      "Epoch 9/50\n",
      " - 6s - loss: 0.0021\n",
      "Epoch 10/50\n",
      " - 7s - loss: 0.0021\n",
      "Epoch 11/50\n",
      " - 7s - loss: 0.0021\n",
      "Epoch 12/50\n",
      " - 6s - loss: 0.0020\n",
      "Epoch 13/50\n",
      " - 7s - loss: 0.0021\n",
      "Epoch 14/50\n",
      " - 6s - loss: 0.0020\n",
      "Epoch 15/50\n",
      " - 7s - loss: 0.0020\n",
      "Epoch 16/50\n",
      " - 6s - loss: 0.0019\n",
      "Epoch 17/50\n",
      " - 7s - loss: 0.0019\n",
      "Epoch 18/50\n",
      " - 7s - loss: 0.0019\n",
      "Epoch 19/50\n",
      " - 7s - loss: 0.0018\n",
      "Epoch 20/50\n",
      " - 7s - loss: 0.0019\n",
      "Epoch 21/50\n",
      " - 7s - loss: 0.0018\n",
      "Epoch 22/50\n",
      " - 7s - loss: 0.0017\n",
      "Epoch 23/50\n",
      " - 6s - loss: 0.0017\n",
      "Epoch 24/50\n",
      " - 6s - loss: 0.0016\n",
      "Epoch 25/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 26/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 27/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 28/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 29/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 30/50\n",
      " - 7s - loss: 0.0014\n",
      "Epoch 31/50\n",
      " - 8s - loss: 0.0016\n",
      "Epoch 32/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 33/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 34/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 35/50\n",
      " - 6s - loss: 0.0015\n",
      "Epoch 36/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 37/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 38/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 39/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 40/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 41/50\n",
      " - 7s - loss: 0.0017\n",
      "Epoch 42/50\n",
      " - 7s - loss: 0.0016\n",
      "Epoch 43/50\n",
      " - 7s - loss: 0.0017\n",
      "Epoch 44/50\n",
      " - 7s - loss: 0.0014\n",
      "Epoch 45/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 46/50\n",
      " - 7s - loss: 0.0014\n",
      "Epoch 47/50\n",
      " - 7s - loss: 0.0014\n",
      "Epoch 48/50\n",
      " - 8s - loss: 0.0015\n",
      "Epoch 49/50\n",
      " - 7s - loss: 0.0015\n",
      "Epoch 50/50\n",
      " - 7s - loss: 0.0014\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8905a4005d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# plot history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network# \n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2243fa13119e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# invert scaling for forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_yhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minv_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minv_yhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
