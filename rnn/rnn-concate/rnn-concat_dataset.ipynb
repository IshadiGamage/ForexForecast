{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "pyplot.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatanating the date and the time stamp into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# with open('concat.csv') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     with open('output.csv', 'w') as g:\n",
    "#         writer = csv.writer(g)\n",
    "#         for row in reader:\n",
    "#             new_row = [' '.join([row[0], row[1]])] + row[2:]\n",
    "#             writer.writerow(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "Date time stamp                                                             \n",
      "0                2016.01.03 17:01             1.08712             1.08712   \n",
      "1                2016.01.03 17:02             1.08708             1.08722   \n",
      "2                2016.01.03 17:03             1.08717             1.08723   \n",
      "3                2016.01.03 17:04             1.08718             1.08718   \n",
      "4                2016.01.03 17:05             1.08703             1.08716   \n",
      "\n",
      "                 Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "Date time stamp                                                  \n",
      "0                          1.08712              1.08712       0  \n",
      "1                          1.08708              1.08722       0  \n",
      "2                          1.08717              1.08723       0  \n",
      "3                          1.08711              1.08711       0  \n",
      "4                          1.08701              1.08712       0  \n",
      "                  Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "Date time stamp                                                             \n",
      "744308           2017.12.29 16:53             1.19972             1.19987   \n",
      "744309           2017.12.29 16:54             1.19985             1.19985   \n",
      "744310           2017.12.29 16:55             1.19969             1.20014   \n",
      "744311           2017.12.29 16:56             1.20009             1.20023   \n",
      "744312           2017.12.29 16:57             1.19982             1.20074   \n",
      "\n",
      "                 Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "Date time stamp                                                  \n",
      "744308                     1.19972              1.19987       0  \n",
      "744309                     1.19970              1.19970       0  \n",
      "744310                     1.19961              1.20010       0  \n",
      "744311                     1.19974              1.19983       0  \n",
      "744312                     1.19980              1.20005       0  \n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "def parse(x):\n",
    "\treturn datetime.strptime(x, '%Y.%m.%d %H:%M')\n",
    "dataset = read_csv('concat.csv', date_parser=parse)\n",
    "#dataset = read_csv('output.csv')\n",
    "#dataset.drop('No', axis=1, inplace=True)\n",
    "\n",
    "# manually specify column names\n",
    "dataset.columns = ['Date time stamp', 'Bar OPEN Bid Quote', 'Bar HIGH Bid Quote', 'Bar LOW Bid Quote', 'Bar CLOSE Bid Quote', 'Volume']\n",
    "dataset.index.name = 'Date time stamp'\n",
    "\n",
    "# mark all NA values with 0\n",
    "dataset['Bar OPEN Bid Quote'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "#dataset = dataset[24:]\n",
    "\n",
    "#dataset.shape()\n",
    "\n",
    "# summarize first 5 rows\n",
    "print(dataset.head(5))\n",
    "print(dataset.tail(5))\n",
    "\n",
    "# save to file\n",
    "dataset.to_csv('2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads the new “2016.csv” file and plots each series as a separate subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "# dataset = read_csv('2016.csv', header=0, index_col=0)\n",
    "# values = dataset.values\n",
    "\n",
    "# # specify columns to plot\n",
    "# groups = [0, 1, 2, 3, 4, 5]\n",
    "# i = 1\n",
    "\n",
    "# # plot each column\n",
    "# pyplot.figure()\n",
    "# for group in groups:\n",
    "# \tpyplot.subplot(len(groups), 1, i)\n",
    "# \tpyplot.plot(values[:, group])\n",
    "# \tpyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "# \ti += 1\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)   var1(t)\n",
      "1   0.000000   0.301724   0.300962   0.303582   0.302078        0.0  0.000001\n",
      "2   0.000001   0.301495   0.301534   0.303353   0.302650        0.0  0.000003\n",
      "3   0.000003   0.302010   0.301592   0.303868   0.302707        0.0  0.000004\n",
      "4   0.000004   0.302067   0.301306   0.303525   0.302021        0.0  0.000005\n",
      "5   0.000005   0.301208   0.301191   0.302953   0.302078        0.0  0.000007\n"
     ]
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('2016.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,0] = encoder.fit_transform(values[:,0])\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[7,8,9,10,11]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM with 50 neurons in the first hidden layer \n",
    "#1 neuron in the output layer for predicting foreign currency rate\n",
    "#The input shape will be 1 time step with 6 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576000, 1, 6) (576000,) (168312, 1, 6) (168312,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets# \n",
    "values = reframed.values\n",
    "n_train_minutes = 200 * 24 * 60 * 2\n",
    "train = values[:n_train_minutes, :]\n",
    "test = values[n_train_minutes:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model will be fit for 50 training epochs with a batch size of 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 576000 samples, validate on 168312 samples\n",
      "Epoch 1/19\n",
      "576000/576000 [==============================] - 15s 25us/step - loss: 0.0018 - acc: 0.0000e+00 - val_loss: 0.0042 - val_acc: 5.9413e-06\n",
      "Epoch 2/19\n",
      "576000/576000 [==============================] - 14s 24us/step - loss: 9.6002e-05 - acc: 0.0000e+00 - val_loss: 9.6481e-04 - val_acc: 5.9413e-06\n",
      "Epoch 3/19\n",
      "576000/576000 [==============================] - 14s 24us/step - loss: 3.3302e-05 - acc: 0.0000e+00 - val_loss: 9.1725e-04 - val_acc: 5.9413e-06\n",
      "Epoch 4/19\n",
      "576000/576000 [==============================] - 16s 27us/step - loss: 2.5915e-05 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 5.9413e-06\n",
      "Epoch 5/19\n",
      "576000/576000 [==============================] - 16s 27us/step - loss: 2.1778e-05 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 5.9413e-06\n",
      "Epoch 6/19\n",
      "576000/576000 [==============================] - 15s 26us/step - loss: 1.8425e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 5.9413e-06\n",
      "Epoch 7/19\n",
      "576000/576000 [==============================] - 16s 29us/step - loss: 1.5176e-05 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 5.9413e-06\n",
      "Epoch 8/19\n",
      "576000/576000 [==============================] - 16s 28us/step - loss: 1.2688e-05 - acc: 0.0000e+00 - val_loss: 0.0018 - val_acc: 5.9413e-06\n",
      "Epoch 9/19\n",
      "576000/576000 [==============================] - 16s 28us/step - loss: 1.1025e-05 - acc: 0.0000e+00 - val_loss: 0.0015 - val_acc: 5.9413e-06\n",
      "Epoch 10/19\n",
      "576000/576000 [==============================] - 16s 28us/step - loss: 9.7717e-06 - acc: 0.0000e+00 - val_loss: 0.0016 - val_acc: 5.9413e-06\n",
      "Epoch 11/19\n",
      "576000/576000 [==============================] - 17s 29us/step - loss: 8.7525e-06 - acc: 0.0000e+00 - val_loss: 0.0017 - val_acc: 5.9413e-06\n",
      "Epoch 12/19\n",
      "576000/576000 [==============================] - 17s 29us/step - loss: 7.8039e-06 - acc: 0.0000e+00 - val_loss: 0.0014 - val_acc: 5.9413e-06\n",
      "Epoch 13/19\n",
      "576000/576000 [==============================] - 16s 29us/step - loss: 7.0121e-06 - acc: 0.0000e+00 - val_loss: 0.0013 - val_acc: 5.9413e-06\n",
      "Epoch 14/19\n",
      "576000/576000 [==============================] - 17s 29us/step - loss: 6.3451e-06 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 5.9413e-06\n",
      "Epoch 15/19\n",
      "576000/576000 [==============================] - 16s 29us/step - loss: 5.8081e-06 - acc: 0.0000e+00 - val_loss: 0.0012 - val_acc: 5.9413e-06\n",
      "Epoch 16/19\n",
      "576000/576000 [==============================] - 17s 29us/step - loss: 5.4167e-06 - acc: 0.0000e+00 - val_loss: 0.0011 - val_acc: 5.9413e-06\n",
      "Epoch 17/19\n",
      "576000/576000 [==============================] - 16s 28us/step - loss: 5.0695e-06 - acc: 0.0000e+00 - val_loss: 7.7844e-04 - val_acc: 5.9413e-06\n",
      "Epoch 18/19\n",
      "576000/576000 [==============================] - 17s 30us/step - loss: 4.8027e-06 - acc: 0.0000e+00 - val_loss: 9.9479e-04 - val_acc: 5.9413e-06\n",
      "Epoch 19/19\n",
      "576000/576000 [==============================] - 17s 29us/step - loss: 4.5687e-06 - acc: 0.0000e+00 - val_loss: 9.9418e-04 - val_acc: 5.9413e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#design network# \n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# model.add(Dense(6, activation='relu'))\n",
    "# #output layer\n",
    "# model.add(Dense(1, activation='linear'))\n",
    "# # efficient gradient descent algorithm - adam\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2]), activation='tanh', return_sequences = True))\n",
    "model.add(LSTM(25, activation = 'tanh'))\n",
    "#model.add(LSTM(6))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "# fit network\n",
    "# batch size-number of instances that are evaluated before a weight update in the network is performed\n",
    "history = model.fit(train_X, train_y, epochs=19,  batch_size=150, validation_data=(test_X, test_y), shuffle=True)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 23468.641\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_4_input to have 3 dimensions, but got array with shape (9912, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5dc5f702af30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    124\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_4_input to have 3 dimensions, but got array with shape (9912, 6)"
     ]
    }
   ],
   "source": [
    "# # evaluate the model\n",
    "# scores = model.evaluate(X, Y)\n",
    "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new instance where we do not know the answer\n",
    "#Xnew = array([[0.29466096, 0.30317302]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "#ynew = model.predict(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the inputs and predicted outputs\n",
    "#print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define one new instance\n",
    "Xnew = (20/1/2017, 1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "ynew = model.predict(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
