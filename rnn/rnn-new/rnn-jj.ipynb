{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 744314\n",
      "Total no: of rows and columns after dropping the rows which contain missing values:  (744314, 6)\n"
     ]
    }
   ],
   "source": [
    "# importing the training set\n",
    "dataset_train = pd.read_csv('concat.csv')\n",
    "\n",
    "# Print the total no of rows in the dataset - dataset_train\n",
    "print(\"Total number of rows: {0}\".format(len(dataset_train)))\n",
    "\n",
    "# Remove all the rows which has all NA values\n",
    "dataset_train.dropna(how=\"all\")\n",
    "\n",
    "\n",
    "# No of rows and columns in the dataset after dropping the rows which contain the missing values\n",
    "print(\"Total no: of rows and columns after dropping the rows which contain missing values: \", dataset_train.shape)\n",
    "\n",
    "training_set = dataset_train.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "0  2016.01.03 17:00             1.08701             1.08713   \n",
      "1  2016.01.03 17:01             1.08712             1.08712   \n",
      "2  2016.01.03 17:02             1.08708             1.08722   \n",
      "3  2016.01.03 17:03             1.08717             1.08723   \n",
      "4  2016.01.03 17:04             1.08718             1.08718   \n",
      "\n",
      "   Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "0            1.08701              1.08713       0  \n",
      "1            1.08712              1.08712       0  \n",
      "2            1.08708              1.08722       0  \n",
      "3            1.08717              1.08723       0  \n",
      "4            1.08711              1.08711       0  \n"
     ]
    }
   ],
   "source": [
    "# print the first 5 rows of the dataset\n",
    "print(dataset_train.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date time stamp  Bar OPEN Bid Quote  Bar HIGH Bid Quote  \\\n",
      "744309  2017.12.29 16:53             1.19972             1.19987   \n",
      "744310  2017.12.29 16:54             1.19985             1.19985   \n",
      "744311  2017.12.29 16:55             1.19969             1.20014   \n",
      "744312  2017.12.29 16:56             1.20009             1.20023   \n",
      "744313  2017.12.29 16:57             1.19982             1.20074   \n",
      "\n",
      "        Bar LOW Bid Quote  Bar CLOSE Bid Quote  Volume  \n",
      "744309            1.19972              1.19987       0  \n",
      "744310            1.19970              1.19970       0  \n",
      "744311            1.19961              1.20010       0  \n",
      "744312            1.19974              1.19983       0  \n",
      "744313            1.19980              1.20005       0  \n"
     ]
    }
   ],
   "source": [
    "# print the last 5 rows of the dataset\n",
    "print(dataset_train.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data structure with 60 time steps and 1 output\n",
    "X_train = []  # input of the neural network\n",
    "y_train = []  # output of the neural network\n",
    "for i in range(60,744313):\n",
    "    X_train.append(training_set_scaled[i-60:i,0])\n",
    "    y_train.append(training_set_scaled[i,0])\n",
    "X_train, y_train = np.array(X_train),np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishadi/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the RNN\n",
    "regressor = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first LSTM layer and some Dropout regularization\n",
    "# units -> no: of neurons\n",
    "# return_sequences -> as a stacked LSTM layers are created return_sequences should be set as True\n",
    "# input_shape -> conatins the last 2 dimensions of the time steps along with the indicators\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "\n",
    "# 20% of the neurons willl be dropeed when training the \n",
    "regressor.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding the second LSTM layer and some Dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the third LSTM layer and some Dropout regularization\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the fourth LSTM layer and some Dropout regularization\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "regressor.add(Dense(units = 1))\n",
    "# activation='linear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the RNN\n",
    "regressor.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "# rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "744253/744253 [==============================] - 5305s 7ms/step - loss: 0.0016 - acc: 2.6873e-06\n",
      "Epoch 2/2\n",
      "744253/744253 [==============================] - 5014s 7ms/step - loss: 9.6621e-04 - acc: 2.6873e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32289b1518>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the RNN to training set\n",
    "# epochs -> no: of iterations neural network wants to be trained\n",
    "regressor.fit(X_train, y_train, epochs = 2, batch_size = 42 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the prediction and visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the real forex rates for 2018\n",
    "dataset_test = pd.read_csv('2018-test_data.csv')\n",
    "real_forex_rate = dataset_test.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the predicted forex rates for 2018\n",
    "# verical concatanation - axis = 0\n",
    "# horizontal concatanation - axis = 1\n",
    "dataset_total = pd.concat((dataset_train['Bar OPEN Bid Quote'], dataset_test['Bar OPEN Bid Quote']), axis = 0)\n",
    "#inputs = dataset_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the RMSE\n",
    "# import math\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# rmse = math.sqrt(mean_squared_error(real_forex_rate, predicted_stock_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-cf6a181f83b6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-cf6a181f83b6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Xnew = (2018/1/20 10:3)\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#new instance where we do not know the answer\n",
    "Xnew = (2018/1/20 10:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a prediction\n",
    "ynew = regressor.predict(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the inputs and predicted outputs\n",
    "#print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
